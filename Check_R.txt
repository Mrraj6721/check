#Prg1
library(dplyr)
n<-as.integer(readline("Enter how many records you want to enter:"))
data<-data.frame(Name=character(),Age=integer(),Salary=double(),stringsAsFactors = FALSE)

for(i in 1:n){
  name<-readline("Name:")
  age<-as.integer(readline("Age "))
  salary<-as.numeric(readline("Salary "))
  data<-rbind(data,data.frame(Name=name,Age=age,Salary=salary))
}

data<-data%>%
  filter(Age>25)%>%
  mutate(Salary*0.2)%>%
  rename(Monthly_Salary=Salary)

print(data)




#Prg2
library(readr)      
library(readxl)      
library(writexl)    
 
csv_data <- read_csv(file.choose()) 
xls_data <- read_excel(file.choose()) 
txt_data <- read_delim(file.choose()) 
 
print(head(csv_data)) 
print(head(xls_data)) 
print(head(txt_data)) 
 
write_csv(csv_data, "exported_data.csv") 
cat("\nCSV Data exported \n") 

write_xlsx(xls_data, "exported_data.xlsx") 
cat("Excel Data exported \n") 
 
write_delim(txt_data, "exported_data.txt") 
cat("TXT Data exported")




#Prg3
install.packages("moments") 
library(moments) 

data <- c(12, 15, 20, 21, 18, 30, 25, 22, 23, 27, 18, 20, 22) 

cat("Data:\n") 
print(data) 
 
cat("\nSummary Statistics:\n") 
print(summary(data)) 

mean_val <- mean(data) 
cat("\nMean:", mean_val, "\n") 

median_val <- median(data) 
cat("Median:", median_val, "\n") 

sd_val <- sd(data) 
cat("Standard Deviation:", sd_val, "\n") 

range_val <- range(data) 
cat("Range:", range_val, "\n") 

par(mfrow=c(1,2)) 
hist(data, main="Histogram of Data", col="skyblue", border="black")





#Prg4
install.packages("mice") 
library(mice) 

data <- data.frame( 
  Age = c(25, NA, 30, NA, 28), 
  Income = c(50000, 60000, NA, 58000, NA) 
) 

print(md.pattern(data)) 

cleaned <- na.omit(data) 
 
imputed <- mice(data, m=1, method='pmm', seed=123) 
completed <- complete(imputed) 

print(cleaned) 
print(completed)




#Prg5
data <- data.frame( 
  ID = 1:5, 
  Marks = c(45, 78, 88, 60, 90) 
) 

normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x))) 
} 
 
data$Normalized_Marks <- normalize(data$Marks) 

cat("Original and Normalized Data:\n") 
print(data)















#PRG 6


# install.packages("ggplot2")
# library(ggplot2)

rm(list = ls())

normal_data <- rnorm(1000, mean = 50, sd = 10)
uniform_data <- runif(1000, min = 30, max = 70)

hist(normal_data,
     main = "Histogram: Normal Distribution",
     xlab = "Value",
     col = "lightblue",
     border = "black")

hist(uniform_data,
     main = "Histogram: Uniform Distribution",
     xlab = "Value",
     col = "lightgreen",
     border = "black")

plot(density(normal_data),
     main = "Density Plot: Normal Distribution",
     xlab = "Value",
     col = "blue",
     lwd = 2)

plot(density(uniform_data),
     main = "Density Plot: Uniform Distribution",
     xlab = "Value",
     col = "green",
     lwd = 2)





# PRG 7
library(ggplot2)
rm(list = ls())

x <- c(1,2,3,4,5,6,7,8,9,10)
y <- c(2,4,5,7,9,10,11,13,14,16)
data <- data.frame(x, y)

model <- lm(y ~ x, data = data)
summary(model)

ggplot(data, aes(x = x, y = y)) +
  geom_point(color = "blue", size = 3) +
  geom_smooth(method = "lm", col = "red", se = FALSE) +
  ggtitle("Simple Linear Regression") +
  xlab("Independent Variable (x)") +
  ylab("Dependent Variable (y)")


Prg 8

library(pROC)

set.seed(123)
data <- data.frame(age=sample(20:60,100,TRUE),
                   income=sample(20000:80000,100,TRUE),
                   buy=sample(c(0,1),100,TRUE))

model <- glm(buy ~ age + income, data=data, family=binomial)

prob <- predict(model, type="response")

roc_obj <- roc(data$buy, prob)
plot(roc_obj, col="blue", main="ROC Curve")
auc(roc_obj)


#Prg 9

library(ggplot2)

set.seed(123)
data <- data.frame(x1=rnorm(100,5,2),
                   x2=rnorm(100,10,3),
                   x3=rnorm(100,15,4))

pca <- prcomp(data, scale.=TRUE)
summary(pca)

ggplot(data.frame(pca$x), aes(PC1, PC2)) +
  geom_point(color="blue") +
  ggtitle("PCA - Dimensionality Reduction")



#Prg 10

library(class)
library(caret)

data(iris)
set.seed(123)
train_index <- sample(1:nrow(iris), 0.7*nrow(iris))
train <- iris[train_index,]
test <- iris[-train_index,]

pred <- knn(train[,1:4], test[,1:4], train$Species, k=3)
confusionMatrix(pred, test$Species)




#Prg 11
library(arules)

data <- list(
  c("milk", "bread", "butter"),
  c("bread", "butter"),
  c("milk", "bread"),
  c("milk", "bread", "butter", "jam"),
  c("bread", "jam")
)

trans <- as(data, "transactions")
rules <- apriori(trans, parameter = list(supp = 0.4, conf = 0.6))
inspect(rules)


#Prg 12
library(ggplot2)

set.seed(123)
data <- data.frame(x=rnorm(100,5,1), y=rnorm(100,10,2))
kmodel <- kmeans(data, centers=3)
data$cluster <- as.factor(kmodel$cluster)

ggplot(data, aes(x, y, color=cluster)) +
  geom_point(size=3) +
  ggtitle("K-Means Clustering")




#Prg 13

data <- c(10, 12, 15, 18, 20, 22, 25, 100)
Q1 <- quantile(data, 0.25)
Q3 <- quantile(data, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
clean_data <- data[data >= lower_bound & data <= upper_bound]
print("Original Data:")
print(data)
print("Cleaned Data (Outliers Removed):")
print(clean_data)




